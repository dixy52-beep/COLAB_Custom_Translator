{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvzeQctWAAP124R/cogNlj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dixy52-beep/COLAB_Custom_Translator/blob/main/Audio-Reconstruction-SuperResolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installare le librerie necessarie\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install tensorflow\n",
        "\n",
        "# Importare le librerie\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "\n",
        "# Funzione per caricare e preprocessare l'audio\n",
        "def load_and_preprocess_audio(audio_path, sr=16000):\n",
        "    # Carica l'audio\n",
        "    original_audio, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "    # Downsampling (bassa qualit√†)\n",
        "    low_quality_audio = librosa.resample(original_audio, orig_sr=sr, target_sr=sr//4)  # Riduci il sample rate a 1/4\n",
        "\n",
        "    # Resample per riportarlo alla dimensione originale\n",
        "    low_quality_audio_upscaled = librosa.resample(low_quality_audio, orig_sr=sr//4, target_sr=sr)\n",
        "\n",
        "    return original_audio, low_quality_audio_upscaled, sr\n",
        "\n",
        "# Funzione per visualizzare i segnali audio\n",
        "def plot_audio_signals(original_audio, low_quality_audio_upscaled, reconstructed_audio, sr):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    plt.subplot(3, 1, 1)\n",
        "    librosa.display.waveshow(original_audio, sr=sr)\n",
        "    plt.title(\"Original Audio\")\n",
        "\n",
        "    plt.subplot(3, 1, 2)\n",
        "    librosa.display.waveshow(low_quality_audio_upscaled, sr=sr)\n",
        "    plt.title(\"Low Quality Audio (Upscaled)\")\n",
        "\n",
        "    plt.subplot(3, 1, 3)\n",
        "    librosa.display.waveshow(reconstructed_audio, sr=sr)\n",
        "    plt.title(\"Reconstructed Audio (Super Resolution)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Funzione per costruire il modello di super-resolution audio\n",
        "def build_audio_super_resolution_model(input_shape):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Primo livello convoluzionale\n",
        "    model.add(layers.Conv1D(64, kernel_size=9, padding='same', input_shape=input_shape))\n",
        "    model.add(layers.Activation('relu'))\n",
        "\n",
        "    # Livelli intermedi convoluzionali\n",
        "    model.add(layers.Conv1D(64, kernel_size=9, padding='same'))\n",
        "    model.add(layers.Activation('relu'))\n",
        "\n",
        "    # Ultimo livello convoluzionale\n",
        "    model.add(layers.Conv1D(1, kernel_size=9, padding='same'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Funzione per dividere l'audio in finestre (segmenti)\n",
        "def prepare_data(audio, window_size=8192):\n",
        "    windows = []\n",
        "    for i in range(0, len(audio) - window_size, window_size):\n",
        "        windows.append(audio[i:i+window_size])\n",
        "    return np.array(windows)\n",
        "\n",
        "# Funzione per ricostruire l'audio\n",
        "def reconstruct_audio(model, low_quality_audio_upscaled, window_size=8192):\n",
        "    reconstructed_audio = []\n",
        "\n",
        "    # Processa ogni finestra e ricostruisci\n",
        "    for i in range(0, len(low_quality_audio_upscaled) - window_size, window_size):\n",
        "        window = low_quality_audio_upscaled[i:i+window_size]\n",
        "        window = np.expand_dims(window, axis=0)  # Aggiungi batch dimension\n",
        "        window = np.expand_dims(window, axis=2)  # Aggiungi dimensione canale\n",
        "        reconstructed_window = model.predict(window)\n",
        "        reconstructed_audio.extend(reconstructed_window.flatten())  # Aggiungi alla ricostruzione totale\n",
        "\n",
        "    # Concatenazione delle finestre\n",
        "    return np.array(reconstructed_audio)\n",
        "\n",
        "# Carica e preprocessa l'audio\n",
        "audio_path = 'Audio.wav'  # Sostituisci con il percorso del tuo file audio\n",
        "original_audio, low_quality_audio_upscaled, sr = load_and_preprocess_audio(audio_path)\n",
        "\n",
        "# Prepara i dati per l'addestramento\n",
        "x_train = prepare_data(low_quality_audio_upscaled)\n",
        "y_train = prepare_data(original_audio)\n",
        "\n",
        "# Reshape per la rete convoluzionale\n",
        "x_train = np.expand_dims(x_train, axis=2)\n",
        "y_train = np.expand_dims(y_train, axis=2)\n",
        "\n",
        "# Costruire il modello\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "model = build_audio_super_resolution_model(input_shape)\n",
        "\n",
        "# Compilare il modello\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Addestrare il modello\n",
        "history = model.fit(x_train, y_train, epochs=250, batch_size=16)\n",
        "\n",
        "# Ricostruire tutto l'audio\n",
        "reconstructed_audio = reconstruct_audio(model, low_quality_audio_upscaled)\n",
        "\n",
        "# Confrontare i segnali audio\n",
        "plot_audio_signals(original_audio[:len(reconstructed_audio)], low_quality_audio_upscaled[:len(reconstructed_audio)], reconstructed_audio, sr)\n",
        "\n",
        "# Salvare i risultati audio\n",
        "sf.write('original_audio.wav', original_audio, sr)\n",
        "sf.write('low_quality_audio_upscaled.wav', low_quality_audio_upscaled, sr)\n",
        "sf.write('reconstructed_audio_full.wav', reconstructed_audio, sr)\n",
        "\n",
        "print(\"Audio salvato: 'original_audio.wav', 'low_quality_audio_upscaled.wav', 'reconstructed_audio_full.wav'\")"
      ],
      "metadata": {
        "id": "AvMxUc_Vsxwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}